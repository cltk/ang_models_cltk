{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1706.03762.pdf\n",
    "http://mlexplained.com/2017/12/29/attention-is-all-you-need-explained/\n",
    "https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/\n",
    "http://jalammar.github.io/illustrated-transformer/\n",
    "https://www.reddit.com/r/MachineLearning/comments/6jdi87/r_question_about_positional_encodings_used_in/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_corpus(filename, tagged=True):\n",
    "    with open(filename, \"r\") as f:\n",
    "        sentences = []\n",
    "        words = {}\n",
    "        for line in f:\n",
    "            sentence = []\n",
    "            pairs = line.rstrip('\\n').split(' ')\n",
    "            for pair in pairs:\n",
    "                if pair != '':\n",
    "                    if tagged == True:\n",
    "                        word, tag = pair.split('/')\n",
    "                        sentence.append((word, tag))\n",
    "                        words[(word, tag)] = words.get((word, tag), 0) + 1                    \n",
    "                    else:\n",
    "                        sentence.append(pair)\n",
    "                        words[pair] = words.get(pair, 0) + 1\n",
    "            sentences.append(sentence)\n",
    "\n",
    "\n",
    "        return words, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, sents = load_corpus('../corpora/oe/oe.all_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_alphabet(words):\n",
    "    alphabet = {}\n",
    "    max_word_len = 0\n",
    "    \n",
    "    for word in words:\n",
    "        max_word_len = max(len(word), max_word_len)\n",
    "        for letter in word:\n",
    "            alphabet[letter] = alphabet.get(letter, 0) + 1\n",
    "            \n",
    "    return list(alphabet.keys()), max_word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, max_word_len = build_alphabet([word for word,_ in words.keys()])\n",
    "max_word_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sent_len = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "feature_names = ['pos', 'person', 'number', 'tense', 'mood', 'voice', 'gender', 'case', 'degree', 'strength', 'inflection']\n",
    "\n",
    "def indexify(string_list):\n",
    "    vocab = list(set(string_list))\n",
    "    return np.asarray([vocab.index(elem)+1 for elem in string_list]), vocab\n",
    "\n",
    "def convert_morphology(tagged_words):\n",
    "    slicers = [(0,2),2,3,4,5,6,7,8,9,10,11]\n",
    "    feature_tags = [[] for _ in slicers]\n",
    "    \n",
    "    for _, tag in tagged_words:\n",
    "        for i, slicer in enumerate(slicers):\n",
    "            start, end = slicer if type(slicer) == tuple else (slicer, slicer + 1)\n",
    "            feature_tags[i].append(tag[start:end])\n",
    "        \n",
    "    vectors = []\n",
    "    label_sets = []\n",
    "    indices = []\n",
    "    for feature in feature_tags:\n",
    "        idx, labels = indexify(feature)\n",
    "        label_sets.append(labels)\n",
    "        indices.append(idx)\n",
    "        vectors.append(to_categorical(idx))\n",
    "        \n",
    "    return vectors, label_sets, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_letter_indices(word, alphabet, max_word_len):\n",
    "    v = np.zeros((max_word_len))\n",
    "    \n",
    "    for i in range(min(len(word), max_word_len)):\n",
    "        v[i] = alphabet.index(word[i]) + 1 if word[i] in alphabet else 0\n",
    "        \n",
    "    return v\n",
    "    \n",
    "def create_char_dataset(tagged_words, sentences, alphabet, max_sent_len, max_word_len):\n",
    "    num_sentences = len(sentences)\n",
    "    X = np.zeros((num_sentences, max_sent_len, max_word_len), dtype='int32')\n",
    "    \n",
    "    tagged_tokens = []\n",
    "    for i, sent in enumerate(sentences):\n",
    "        sent_len = len(sent)\n",
    "        for j, (word, tag) in enumerate(sent):\n",
    "            if j >= max_sent_len:\n",
    "                break\n",
    "            tagged_tokens.append((word, tag))\n",
    "            X[i, j, :] = select_letter_indices(word, alphabet, max_word_len)\n",
    "        \n",
    "    features, labels, _ = convert_morphology(tagged_tokens)\n",
    "    \n",
    "    Y = [np.zeros((num_sentences, max_sent_len, F.shape[1])) for F in features]\n",
    "    i = 0\n",
    "    for j, sent in enumerate(sentences):\n",
    "        for k in range(min(max_sent_len, len(sent))):\n",
    "            for f in range(len(features)):\n",
    "                Y[f][j, k, :] = features[f][i]\n",
    "            i += 1\n",
    "\n",
    "    return X, Y, labels, tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(sents)\n",
    "X, Y, labels, _ = create_char_dataset(words, sents, alpha, max_sent_len, max_word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2536, 48, 12), (2536, 48, 19))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = X[-110:], [y[-110:] for y in Y]\n",
    "X = X[:-110]\n",
    "Y = [y[:-110] for y in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(filename):\n",
    "    vocab = {}\n",
    "    rev_vocab = {}\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        for pair in f:\n",
    "            idx, word = pair.split()\n",
    "            vocab[word] = int(idx)\n",
    "            rev_vocab[int(idx)] = word\n",
    "            \n",
    "    return vocab, rev_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, rev_vocab = load_vocab('../models/oe/oe_types.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325198"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_vectors(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        vectors = pickle.load(f)\n",
    "        \n",
    "    vectors = np.concatenate([np.zeros((1,300)),vectors],axis=0)\n",
    "    norm_vectors = np.divide(vectors, np.linalg.norm(vectors, axis=-1, keepdims=True))\n",
    "    norm_vectors[0] = 0\n",
    "    \n",
    "    return norm_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jds/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "vectors = load_vectors('../models/oe/oe_vectors.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_dataset(sentences, vocab, max_sent_len):\n",
    "    X = np.zeros((len(sentences), max_sent_len))\n",
    "    for i, sent in enumerate(sentences):\n",
    "        for j, (word, _) in enumerate(sent):\n",
    "            if j == max_sent_len:\n",
    "                break\n",
    "            X[i,j] = vocab[word]\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = create_word_dataset(sents, vocab, max_sent_len)\n",
    "X2_train = X2[:-110]\n",
    "X2_test = X2[-110:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def positional_encoding(max_sent_len, num_dims):\n",
    "    pos_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (i // 2) / num_dims) for i in range(num_dims)] \n",
    "        if pos != 0 else np.zeros(num_dims) \n",
    "        for pos in range(max_sent_len)])\n",
    "    \n",
    "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
    "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
    "    \n",
    "    return K.constant(pos_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Input\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "    \n",
    "\n",
    "def make_transformer(\n",
    "    word_vectors,\n",
    "    max_sent_len, \n",
    "    morpho_sizes,\n",
    "    morpho_names,\n",
    "    d_model):\n",
    "    \n",
    "    # The Word portion\n",
    "    # word vectors\n",
    "    word_embed = layers.Embedding(word_vectors.shape[0],\n",
    "                                  word_vectors.shape[1],\n",
    "                                  input_length=max_sent_len,\n",
    "                                  weights=[word_vectors],\n",
    "                                  trainable = False,\n",
    "                                  mask_zero = True)\n",
    "    \n",
    "    word_input = Input(shape=(max_sent_len,), dtype='float32')\n",
    "    word_vectors = word_embed(word_input)\n",
    "    word_vectors = layers.Dense(d_model)(word_vectors)\n",
    "    \n",
    "    positional_encodings = positional_encoding(max_sent_len, d_model)\n",
    "    \n",
    "    word_pos_vectors = layers.Lambda(lambda x: np.add(x, positional_encodings))(word_vectors)\n",
    "    \n",
    "   \n",
    "    out = word_pos_vectors\n",
    "    outputs = [layers.Dense(morpho_size, activation='softmax', name=morpho_names[i])(out) for i, morpho_size in enumerate(morpho_sizes)]\n",
    "\n",
    "    \n",
    "    model = Model(word_input, outputs)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 48, 300)      97559700    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 48, 200)      60200       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 48, 200)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pos (Dense)                     (None, 48, 19)       3819        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "person (Dense)                  (None, 48, 6)        1206        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "number (Dense)                  (None, 48, 6)        1206        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tense (Dense)                   (None, 48, 4)        804         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mood (Dense)                    (None, 48, 8)        1608        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "voice (Dense)                   (None, 48, 2)        402         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 48, 10)       2010        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "case (Dense)                    (None, 48, 10)       2010        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "degree (Dense)                  (None, 48, 7)        1407        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "strength (Dense)                (None, 48, 5)        1005        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "inflection (Dense)              (None, 48, 3)        603         lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 97,635,980\n",
      "Trainable params: 76,280\n",
      "Non-trainable params: 97,559,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "m1 = make_transformer(vectors, \n",
    "                      max_sent_len,\n",
    "                      [y.shape[2] for y in Y],\n",
    "                      feature_names, 200)\n",
    "m1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A callback will help visualize the training process.  Three plots will be produced:\n",
    "\n",
    "1.  Training and validation losses.\n",
    "2.  Training accuracy for each feature type.\n",
    "3.  Validation accuracy for each feature type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class PlotLosses(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.accs = {}\n",
    "        self.val_accs = {}\n",
    "        for f in feature_names:\n",
    "            self.accs[f] = []\n",
    "            self.val_accs[f] = []\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        \n",
    "        for f in feature_names:\n",
    "            self.accs[f].append(logs.get(f + '_acc'))\n",
    "            self.val_accs[f].append(logs.get('val_' + f + '_acc'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        _, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=True, figsize=(20, 10))\n",
    "        ax1.plot(self.x, self.losses, label=\"loss\")\n",
    "        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        \n",
    "        for f in feature_names:\n",
    "            ax2.plot(self.x, self.accs[f], label=(f + \"_acc\"))\n",
    "            ax3.plot(self.x, self.val_accs[f], label=\"val_\" + f + \"_acc\")\n",
    "            \n",
    "        ax1.legend()\n",
    "        ax2.legend()\n",
    "        ax3.legend()\n",
    "        plt.show();\n",
    "        \n",
    "        for f in feature_names:\n",
    "            print(f +  \" best:\", np.round(np.max(self.val_accs[f]), 3), \"last:\", np.round(self.val_accs[f][-1], 3))\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train the model.  A smaller batch-size seems to work earlier on, though in a careful training regime it emerges that increasing the batch size later yields slightly higher test accuracy.\n",
    "\n",
    "We will split the training dataset again 95/05 so that a validation (\"dev\") set will provide information about the fitting process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2304 samples, validate on 122 samples\n",
      "Epoch 1/10\n",
      "  80/2304 [>.............................] - ETA: 12:25 - loss: 5.3571 - pos_loss: 0.8107 - person_loss: 0.3706 - number_loss: 0.3781 - tense_loss: 0.4364 - mood_loss: 0.5364 - voice_loss: 0.2712 - gender_loss: 0.6464 - case_loss: 0.6260 - degree_loss: 0.4755 - strength_loss: 0.5993 - inflection_loss: 0.2066 - pos_acc: 0.0208 - person_acc: 0.0891 - number_acc: 0.0729 - tense_acc: 0.0328 - mood_acc: 0.0245 - voice_acc: 0.5594 - gender_acc: 0.0372 - case_acc: 0.0383 - degree_acc: 0.3367 - strength_acc: 0.0612 - inflection_acc: 0.1919"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-301c8f74d62b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                  validation_split = 0.05)\n\u001b[0m",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = m1.fit(X2_train, [y for y in Y],\n",
    "                 batch_size=16, epochs=10,\n",
    "                 callbacks=[plot_losses],\n",
    "                 validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Let's evaluate the model against the test set, the same that was used in evaluating the Perceptron tagger above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "110/110 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'case': 0.858,\n",
       " 'degree': 0.935,\n",
       " 'gender': 0.858,\n",
       " 'inflection': 0.965,\n",
       " 'mood': 0.967,\n",
       " 'number': 0.91,\n",
       " 'person': 0.979,\n",
       " 'pos': 0.918,\n",
       " 'strength': 0.954,\n",
       " 'tense': 0.979,\n",
       " 'voice': 1.0}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(feature_names, np.round(m1.evaluate([X_test, X2_test], [y for y in  Y_test], batch_size=256)[-11:], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing this result to the Perceptron tagger above, we see that the Word+Char model improves on NLTK's AveragedPerceptron across all features, and especially so for the POS tagging task.  \n",
    "\n",
    "The POS accuracy of 0.918 puts the Word+Char in the range of the Germanic taggers tested by Horsmann and Zesch, though somewhat on the lower end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Perceptron Tagger | Word+Char LSTM | Diff |\n",
    "----------|-------------------|----------------|------|\n",
    "|  POS | 0.840 | 0.918 | + 7.8% |\n",
    "| Person | 0.956 | 0.979 | + 2.3% |\n",
    "| Number | 0.827 | 0.91 | + 9.3% |\n",
    "| Tense | 0.960 | 0.979 | + 3.9% |\n",
    "| Mood | 0.952 | 0.967 | + 1.5% |\n",
    "| Gender | 0.798 | 0.858 | + 6.0% |\n",
    "| Case | 0.814 | 0.858 | + 4.4 % |\n",
    "| Degree | 0.907 | 0.935 | + 2.8% |\n",
    "| Strength | 0.927 | 0.954 | + 2.7% |\n",
    "| Inflection | 0.931 | 0.965 | + 3.4% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_full = [\n",
    "    ['interrogative adverb', 'quantifier', 'foreign word','conjunction','possessive pronoun', 'personal pronoun',\n",
    "     'inifnitive marker','subjunction','adverb','interrogative pronoun',\n",
    "     'adjective','indefinite pronoun','verb','interjection',\n",
    "     'proper noun','preposition','common noun','demonstrative pronoun'],\n",
    "    ['second person', 'third person', 'none', 'first person', 'uncertain person'],\n",
    "    ['dual', 'none', 'singular', 'plural', 'uncertain number'],\n",
    "    ['past', 'none', 'present'],\n",
    "    ['imperative', 'none', 'subjunctive', 'participle', 'infinitive','uncertain mood', 'indicative'],\n",
    "    ['none'],\n",
    "    ['masculine', 'feminine', 'none', 'masculine or feminine', 'masculine or neuter', 'neuter', 'uncertain gender', 'feminine or neuter', 'masculine, feminine or neuter'],\n",
    "    ['none', 'oblique', 'accusative', 'nominative', 'dative', 'genitive', 'uncertain case', 'no case', 'instrumental'],\n",
    "    ['comparative', 'none', 'superlative', 'positive', 'uncertain degree' ,'no degree'],\n",
    "    ['weak or strong' ,'weak', 'none', 'strong'],\n",
    "    ['non-inflecting', 'inflecting']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------  pos  ----------------\n",
      "                      |                   d           i                             |\n",
      "                      |                   e       i   n                             |\n",
      "                      |                   m       n   t                             |\n",
      "                      |                   o   i   t   e       p                     |\n",
      "                      |                   n   n   e   r       o                     |\n",
      "                      |                   s   d   r   r   p   s                     |\n",
      "                      |                   t   e   r   o   e   s                     |\n",
      "                      |                   r   f   o   g   r   e                     |\n",
      "                      |                   a   i   g   a   s   s                     |\n",
      "                      |                   t   n   a   t   o   s                     |\n",
      "                      |           c   c   i   i   t   i   n   i   p   p       s     |\n",
      "                      |           o   o   v   t   i   v   a   v   r   r   q   u     |\n",
      "                      |   a       m   n   e   e   v   e   l   e   e   o   u   b     |\n",
      "                      |   d       m   j           e               p   p   a   j     |\n",
      "                      |   j       o   u   p   p       p   p   p   o   e   n   u     |\n",
      "                      |   e   a   n   n   r   r   a   r   r   r   s   r   t   n     |\n",
      "                      |   c   d       c   o   o   d   o   o   o   i       i   c     |\n",
      "                      |   t   v   n   t   n   n   v   n   n   n   t   n   f   t   v |\n",
      "                      |   i   e   o   i   o   o   e   o   o   o   i   o   i   i   e |\n",
      "                      |   v   r   u   o   u   u   r   u   u   u   o   u   e   o   r |\n",
      "                      |   e   b   n   n   n   n   b   n   n   n   n   n   r   n   b |\n",
      "----------------------+-------------------------------------------------------------+\n",
      "            adjective | <60>  .  11   .   .   .   .   .   .   .   .   1   .   .   6 |\n",
      "               adverb |   5<146>  2   .   2   .   .   .   .   .   1   .   .   2   6 |\n",
      "          common noun |   5   .<248>  .   .   1   .   .   .   1   .   .   .   .   9 |\n",
      "          conjunction |   .   .   1<117>  .   .   .   .   .   .   .   .   .   2   1 |\n",
      "demonstrative pronoun |   .   3   .   .<145>  .   .   .   .   .   .   .   .   2   1 |\n",
      "   indefinite pronoun |   .   .   4   .   .  <7>  .   .   .   .   .   .   .   .   . |\n",
      " interrogative adverb |   .   .   .   .   .   .  <2>  .   .   .   .   .   .   .   . |\n",
      "interrogative pronoun |   .   1   .   .   .   .   .  <2>  .   .   .   .   .   .   . |\n",
      "     personal pronoun |   .   .   .   .   .   .   .   .<130>  2   .   .   .   .   . |\n",
      "   possessive pronoun |   .   .   .   .   .   .   .   .   1 <28>  .   .   .   .   . |\n",
      "          preposition |   .   4   3   .   .   .   .   .   .   .<163>  .   4   .   . |\n",
      "          proper noun |   1   .   .   .   .   .   .   .   .   1   . <95>  .   .   . |\n",
      "           quantifier |  10   .   5   2   .   .   .   .   3   .   .   7 <95>  .   3 |\n",
      "          subjunction |   .  10   .   .   6   .   .   .   .   .   4   .   . <58>  . |\n",
      "                 verb |   1   .   5   .   .   .   .   .   .   .   .   .   .   .<266>|\n",
      "----------------------+-------------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "----------------  person  ----------------\n",
      "              |              s      |\n",
      "              |    f         e    t |\n",
      "              |    i         c    h |\n",
      "              |    r         o    i |\n",
      "              |    s         n    r |\n",
      "              |    t         d    d |\n",
      "              |                     |\n",
      "              |    p         p    p |\n",
      "              |    e         e    e |\n",
      "              |    r    n    r    r |\n",
      "              |    s    o    s    s |\n",
      "              |    o    n    o    o |\n",
      "              |    n    e    n    n |\n",
      "--------------+---------------------+\n",
      " first person |   <2>   .    .    . |\n",
      "         none |    2<1323>   1   21 |\n",
      "second person |    .    .   <.>   1 |\n",
      " third person |    .    8    3 <340>|\n",
      "--------------+---------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "----------------  number  ----------------\n",
      "                 |               u |\n",
      "                 |               n |\n",
      "                 |               c |\n",
      "                 |               e |\n",
      "                 |               r |\n",
      "                 |               t |\n",
      "                 |               a |\n",
      "                 |               i |\n",
      "                 |           s   n |\n",
      "                 |           i     |\n",
      "                 |       p   n   n |\n",
      "                 |       l   g   u |\n",
      "                 |   n   u   u   m |\n",
      "                 |   o   r   l   b |\n",
      "                 |   n   a   a   e |\n",
      "                 |   e   l   r   r |\n",
      "-----------------+-----------------+\n",
      "            none |<574>  3  33   . |\n",
      "          plural |   5<206> 39   2 |\n",
      "        singular |  12  22<730>  4 |\n",
      "uncertain number |   4   8  21 <38>|\n",
      "-----------------+-----------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "----------------  tense  ----------------\n",
      "        |              p |\n",
      "        |              r |\n",
      "        |              e |\n",
      "        |    n    p    s |\n",
      "        |    o    a    e |\n",
      "        |    n    s    n |\n",
      "        |    e    t    t |\n",
      "--------+----------------+\n",
      "   none |<1435>  14    8 |\n",
      "   past |    6 <183>   4 |\n",
      "present |    2    1  <48>|\n",
      "--------+----------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "----------------  mood  ----------------\n",
      "               |                                  u |\n",
      "               |                                  n |\n",
      "               |                                  c |\n",
      "               |                             s    e |\n",
      "               |    i    i    i         p    u    r |\n",
      "               |    m    n    n         a    b    t |\n",
      "               |    p    d    f         r    j    a |\n",
      "               |    e    i    i         t    u    i |\n",
      "               |    r    c    n         i    n    n |\n",
      "               |    a    a    i         c    c      |\n",
      "               |    t    t    t    n    i    t    m |\n",
      "               |    i    i    i    o    p    i    o |\n",
      "               |    v    v    v    n    l    v    o |\n",
      "               |    e    e    e    e    e    e    d |\n",
      "---------------+------------------------------------+\n",
      "    imperative |   <1>   .    .    .    .    .    . |\n",
      "    indicative |    1 <134>   2    2    .    4    7 |\n",
      "    infinitive |    .    .  <24>   3    .    .    . |\n",
      "          none |    .   10    3<1402>   6    2    6 |\n",
      "    participle |    .    1    .    3  <19>   .    . |\n",
      "   subjunctive |    .    .    .    .    1  <11>   1 |\n",
      "uncertain mood |    .    .    .    .    1    3  <54>|\n",
      "---------------+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "----------------  voice  ----------------\n",
      "     |    n |\n",
      "     |    o |\n",
      "     |    n |\n",
      "     |    e |\n",
      "-----+------+\n",
      "none |<1701>|\n",
      "-----+------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "----------------  gender  ----------------\n",
      "                              |               m             |\n",
      "                              |               a             |\n",
      "                              |               s             |\n",
      "                              |               c             |\n",
      "                              |               u             |\n",
      "                              |               l             |\n",
      "                              |               i             |\n",
      "                              |               n             |\n",
      "                              |               e             |\n",
      "                              |               ,             |\n",
      "                              |           m                 |\n",
      "                              |           a   f             |\n",
      "                              |           s   e             |\n",
      "                              |           c   m           u |\n",
      "                              |           u   i           n |\n",
      "                              |           l   n           c |\n",
      "                              |           i   i           e |\n",
      "                              |           n   n           r |\n",
      "                              |           e   e           t |\n",
      "                              |                           a |\n",
      "                              |       m   o   o           i |\n",
      "                              |   f   a   r   r           n |\n",
      "                              |   e   s                     |\n",
      "                              |   m   c   n   n   n       g |\n",
      "                              |   i   u   e   e   e       e |\n",
      "                              |   n   l   u   u   u   n   n |\n",
      "                              |   i   i   t   t   t   o   d |\n",
      "                              |   n   n   e   e   e   n   e |\n",
      "                              |   e   e   r   r   r   e   r |\n",
      "------------------------------+-----------------------------+\n",
      "                     feminine | <87> 25   .   .   6   2   1 |\n",
      "                    masculine |  12<361>  .   .  27  12   9 |\n",
      "          masculine or neuter |   .   .  <.>  .   2   .   . |\n",
      "masculine, feminine or neuter |   .   1   .  <.>  .   .   . |\n",
      "                       neuter |   7  39   .   .<164> 12   8 |\n",
      "                         none |   6  19   .   .   7<800>  1 |\n",
      "             uncertain gender |   1  31   .   .   6   8 <47>|\n",
      "------------------------------+-----------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "----------------  case  ----------------\n",
      "               |                           u |\n",
      "               |                           n |\n",
      "               |               i           c |\n",
      "               |               n           e |\n",
      "               |   a           s   n       r |\n",
      "               |   c           t   o       t |\n",
      "               |   c       g   r   m       a |\n",
      "               |   u       e   u   i       i |\n",
      "               |   s   d   n   m   n       n |\n",
      "               |   a   a   i   e   a         |\n",
      "               |   t   t   t   n   t   n   c |\n",
      "               |   i   i   i   t   i   o   a |\n",
      "               |   v   v   v   a   v   n   s |\n",
      "               |   e   e   e   l   e   e   e |\n",
      "---------------+-----------------------------+\n",
      "    accusative |<123>  3   1   1  45  14   5 |\n",
      "        dative |   6<188>  1   1   2   3  10 |\n",
      "      genitive |   2   4 <65>  .   9   3   2 |\n",
      "  instrumental |   4   .   .  <2>  .   .   . |\n",
      "    nominative |  30   3   1   .<234>  7   8 |\n",
      "          none |   8   7   3   .  14<797>  3 |\n",
      "uncertain case |   7  12   2   .  16   5 <50>|\n",
      "---------------+-----------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "----------------  degree  ----------------\n",
      "                 |                             u |\n",
      "                 |                             n |\n",
      "                 |                             c |\n",
      "                 |                             e |\n",
      "                 |                             r |\n",
      "                 |    c                   s    t |\n",
      "                 |    o                   u    a |\n",
      "                 |    m    n              p    i |\n",
      "                 |    p    o         p    e    n |\n",
      "                 |    a              o    r      |\n",
      "                 |    r    d         s    l    d |\n",
      "                 |    a    e         i    a    e |\n",
      "                 |    t    g    n    t    t    g |\n",
      "                 |    i    r    o    i    i    r |\n",
      "                 |    v    e    n    v    v    e |\n",
      "                 |    e    e    e    e    e    e |\n",
      "-----------------+-------------------------------+\n",
      "     comparative |   <3>   .    4    4    .    . |\n",
      "       no degree |    .  <46>  11    8    .    . |\n",
      "            none |    .    5<1430>  10    .    . |\n",
      "        positive |    .    5   31 <102>   1    . |\n",
      "     superlative |    .    .    2    4   <9>   . |\n",
      "uncertain degree |    1   16    8    1    .   <.>|\n",
      "-----------------+-------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "----------------  strength  ----------------\n",
      "               |                   w |\n",
      "               |                   e |\n",
      "               |                   a |\n",
      "               |                   k |\n",
      "               |                     |\n",
      "               |                   o |\n",
      "               |                   r |\n",
      "               |                     |\n",
      "               |         s         s |\n",
      "               |         t         t |\n",
      "               |    n    r    w    r |\n",
      "               |    o    o    e    o |\n",
      "               |    n    n    a    n |\n",
      "               |    e    g    k    g |\n",
      "---------------+---------------------+\n",
      "          none |<1459>  17    1    1 |\n",
      "        strong |   17 <101>   3    8 |\n",
      "          weak |    1    .  <17>   . |\n",
      "weak or strong |   21   10    .  <45>|\n",
      "---------------+---------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "----------------  inflection  ----------------\n",
      "               |         n |\n",
      "               |         o |\n",
      "               |         n |\n",
      "               |         - |\n",
      "               |    i    i |\n",
      "               |    n    n |\n",
      "               |    f    f |\n",
      "               |    l    l |\n",
      "               |    e    e |\n",
      "               |    c    c |\n",
      "               |    t    t |\n",
      "               |    i    i |\n",
      "               |    n    n |\n",
      "               |    g    g |\n",
      "---------------+-----------+\n",
      "    inflecting |<1116>  32 |\n",
      "non-inflecting |   27 <526>|\n",
      "---------------+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "\n",
    "predicted = m1.predict([X_test, X2_test])\n",
    "\n",
    "for i in range(len(predicted)):\n",
    "    print('---------------- ', feature_names[i], ' ----------------')\n",
    "    gold = np.ndarray.flatten(np.argmax(Y_test[i], axis=2))\n",
    "    mask = gold > 0\n",
    "    pred = np.ndarray.flatten(np.argmax(predicted[i], axis=2))\n",
    "    \n",
    "    gold_labels = [labels_full[i][idx-1] for idx in gold[mask]]\n",
    "    pred_labels = [labels_full[i][idx-1] for idx in pred[mask]]\n",
    "    print(ConfusionMatrix(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few considerations:\n",
    "\n",
    "* POS tagging, there is some equivocation between adjectives and nouns, perhaps explained by the observation that in OE adjectives are inflected like nouns for case, gender, number.  Also, because of its relatively free word order, adjectives are not predictable pre- or post-nominal or in predicate position.\n",
    "* Another issue for POS tagging is the \"subjunction\" annotation, which the tagger frequently mis-tags as adverbial.  These \"subjuction\" elements appear to be complementizers, such as *þy* \"therefore, because\", which might rightly be tagged as adverbial, i.e. merged in A-bar positions.\n",
    "* Forms annotated as quantifiers are tagged as adjectives by the classifier.  This again is linguistically defensible, as words like *micel* \"much, big, a lot\" and *manig* \"many\" are sometimes classed as adjectives (e.g. by [Wiktionary](https://en.wiktionary.org/wiki/manig))\n",
    "* As for case, there is a predictable equivocation between nominative and accusative case assignment.  This is due to syncretism in OE's case system: nominative and accusative forms overlap in cells of the nominal and adjectival paradigms -- principally in masculine and neuter lemmas --, and since word order is only weakly driven by syntax, disambiguation is difficult.\n",
    "* The last point might also explain the system's lack of accuracy in distinguishing masculine from neuter forms. Its apparent difficulty in distinguishing feminine from masculine forms likely lies in the phonological heterogeneity of the categories: on encountering a new word, it is difficult to guess at its gender from its form.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Productification\n",
    "\n",
    "To be useful in practice, the model parameters must be exported, and the preprocessing routines wrappend in a library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_morpho_model(path, model, alphabet, feature_names, labels):\n",
    "    model.save(path + \"/\" + 'morpho_model.h5')\n",
    "        \n",
    "    with open(path + '/' + 'alphabet.pickle', 'wb') as out:\n",
    "        pickle.dump(alphabet, out)\n",
    "        \n",
    "    with open(path + '/' + 'feature_names.pickle', 'wb') as out:\n",
    "        pickle.dump(feature_names, out)\n",
    "    \n",
    "    with open(path + '/' + 'labels.pickle', 'wb') as out:\n",
    "        pickle.dump(labels, out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_morpho_model('../models/oe', m1, alpha, feature_names, labels_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loading of the model, the preprocessing and the tagging are best wrapped into a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "class MorphologicalAnalyzer:\n",
    "    def __init__(self, path):\n",
    "        \"\"\"Loads the model from a saved HDF5 file,\n",
    "        along with related data structures for taglibs and vocabularies.\"\"\"\n",
    "        \n",
    "        self.model = load_model(path + '/' + 'morpho_model.h5')\n",
    "\n",
    "        with open(path + '/' + 'alphabet.pickle', 'rb') as inp:\n",
    "            self.alphabet = pickle.load(inp)\n",
    "\n",
    "        with open(path + '/' + 'feature_names.pickle', 'rb') as inp:\n",
    "            self.feature_names = pickle.load(inp)\n",
    "\n",
    "        with open(path + '/' + 'labels.pickle', 'rb') as inp:\n",
    "            self.labels = pickle.load(inp)\n",
    "\n",
    "        input_layer = self.model.get_layer(index=0)\n",
    "\n",
    "        self.max_sent_len = input_layer.input_shape[1]\n",
    "        self.max_word_len = input_layer.input_shape[2]\n",
    "        \n",
    "        self.vocab = {}\n",
    "        with open(path + '/' + 'oe_types.txt', 'r') as f:\n",
    "            for pair in f:\n",
    "                idx, word = pair.split()\n",
    "                self.vocab[word] = int(idx)\n",
    "                \n",
    "        \n",
    "    def _select_letter_indices(self, word):\n",
    "        \"\"\"For an input words, returns a vector of indices into the alphabet.\"\"\"\n",
    "        v = np.zeros((self.max_word_len))\n",
    "    \n",
    "        for i in range(min(len(word), self.max_word_len)):\n",
    "            v[i] = self.alphabet.index(word[i]) + 1 if word[i] in self.alphabet else 0\n",
    "\n",
    "        return v\n",
    "        \n",
    "    def _characterize(self, sentences):\n",
    "        \"\"\"For a list of sentences, returns a tensor of dimension \n",
    "        (num sentences, words_per_sentence, letters_per_word)\n",
    "        of indices into the alphabet.\"\"\"\n",
    "        \n",
    "        X = np.zeros((len(sentences), self.max_sent_len, self.max_word_len), dtype='int32')\n",
    "    \n",
    "        for i, sent in enumerate(sentences):\n",
    "            for j, word in enumerate(sent):\n",
    "                if j >= self.max_sent_len:\n",
    "                    break\n",
    "                X[i, j, :] = self._select_letter_indices(word)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def _wordize(self, sentences):\n",
    "        \"\"\"For a list of sentences, returns a tensor of dimension\n",
    "        (num_sentences, words_per_sentence)\n",
    "        of indices into the vocabulary.\"\"\"\n",
    "        \n",
    "        X = np.zeros((len(sentences), self.max_sent_len))\n",
    "        for i, sent in enumerate(sentences):\n",
    "            for j, word in enumerate(sent):\n",
    "                if j == self.max_sent_len:\n",
    "                    break\n",
    "                X[i,j] = self.vocab[word] + 1 if word in self. vocab else 0\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        \"\"\"Tokenizes a text into sentences and words (list of list of strings) if necessary,\n",
    "        and maps the tokens to indices into the vocabulary and the alphabet,\n",
    "        returning a 3D tensor for the characters and 2D tensor for the words.\"\"\"\n",
    "        \n",
    "        if type(text) != list:\n",
    "            text = text.replace('!','.') \n",
    "            text = text.replace(',', ' ')\n",
    "            sents = [word_tokenize(sent) for sent in sent_tokenize(text)]\n",
    "        else:\n",
    "            sents = text\n",
    "        \n",
    "        X1 = self._characterize(sents)\n",
    "        X2 = self._wordize(sents)\n",
    "        \n",
    "        return sents, X1, X2\n",
    "        \n",
    "    def tag(self, text):\n",
    "        \"\"\"Takes a text as a string or a list of list of string tokens,\n",
    "        returning a list of list of tuples (word, feature_bundle),\n",
    "        where feature_bundle is a dict of feature to feature_value.\"\"\"\n",
    "        \n",
    "        sentences, X1, X2 = self.preprocess(text)\n",
    "        pred = self.model.predict([X1, X2], verbose=1, batch_size=32)\n",
    "        tagged_sents = []\n",
    "\n",
    "        for i, sent in enumerate(sentences):\n",
    "            tagged_sent = []\n",
    "            for j, word in enumerate(sent):\n",
    "                if j == self.max_sent_len:\n",
    "                    break\n",
    "                feature_bundle = {}\n",
    "                for k, feature_name in enumerate(self.feature_names):\n",
    "                    feature_value = self.labels[k][np.argmax(pred[k][i,j])-1]\n",
    "                    if feature_value != 'none':\n",
    "                        feature_bundle[feature_name] = feature_value\n",
    "                tagged_sent.append((word, feature_bundle))\n",
    "            tagged_sents.append(tagged_sent)\n",
    "        \n",
    "        return tagged_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 38.78066349029541 seconds ----\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "morph_anal = MorphologicalAnalyzer('../models/oe')\n",
    "print(\"---- {0} seconds ----\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,everything = load_corpus('../texts/oe/oe_all.txt', tagged=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110656/110656 [==============================] - 649s 6ms/step\n",
      "---- 706.1857607364655 seconds ----\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "tags = morph_anal.tag(everything)\n",
    "print(\"---- {0} seconds ----\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "105 seconds for about 1.5MM words translates to a rate of ~ 145,000 words/sec.  This compares favourably with the ~10,000 words/sec for just one feaature (POS) turned in by the Perceptron tagger.  Of course the hardware plays a huge role here: I'm using a GTX 1080Ti to accelerate the tensorflow computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Us',\n",
       "  {'inflection': 'inflecting',\n",
       "   'number': 'singular',\n",
       "   'person': 'first person',\n",
       "   'pos': 'personal pronoun'}),\n",
       " ('is',\n",
       "  {'inflection': 'inflecting',\n",
       "   'mood': 'indicative',\n",
       "   'number': 'singular',\n",
       "   'person': 'third person',\n",
       "   'pos': 'verb',\n",
       "   'tense': 'present'}),\n",
       " ('riht', {'degree': 'positive', 'inflection': 'inflecting', 'pos': 'adverb'}),\n",
       " ('micel',\n",
       "  {'case': 'nominative',\n",
       "   'degree': 'positive',\n",
       "   'gender': 'neuter',\n",
       "   'inflection': 'inflecting',\n",
       "   'number': 'singular',\n",
       "   'pos': 'quantifier',\n",
       "   'strength': 'strong'}),\n",
       " ('ðæt', {'inflection': 'non-inflecting', 'pos': 'subjunction'}),\n",
       " ('we',\n",
       "  {'case': 'nominative',\n",
       "   'inflection': 'inflecting',\n",
       "   'number': 'plural',\n",
       "   'person': 'first person',\n",
       "   'pos': 'personal pronoun'}),\n",
       " ('rodera',\n",
       "  {'case': 'genitive',\n",
       "   'gender': 'masculine',\n",
       "   'inflection': 'inflecting',\n",
       "   'number': 'plural',\n",
       "   'pos': 'common noun'}),\n",
       " ('weard,',\n",
       "  {'degree': 'positive',\n",
       "   'gender': 'neuter',\n",
       "   'inflection': 'inflecting',\n",
       "   'number': 'singular',\n",
       "   'pos': 'common noun'}),\n",
       " ('wereda',\n",
       "  {'case': 'genitive',\n",
       "   'gender': 'neuter',\n",
       "   'inflection': 'inflecting',\n",
       "   'number': 'plural',\n",
       "   'pos': 'common noun'}),\n",
       " ('wuldorcining,',\n",
       "  {'case': 'accusative',\n",
       "   'gender': 'neuter',\n",
       "   'inflection': 'inflecting',\n",
       "   'number': 'singular',\n",
       "   'pos': 'common noun'}),\n",
       " ('wordum',\n",
       "  {'case': 'dative',\n",
       "   'gender': 'neuter',\n",
       "   'inflection': 'inflecting',\n",
       "   'number': 'plural',\n",
       "   'pos': 'common noun'}),\n",
       " ('herigen,',\n",
       "  {'case': 'uncertain case',\n",
       "   'degree': 'positive',\n",
       "   'gender': 'neuter',\n",
       "   'inflection': 'inflecting',\n",
       "   'number': 'plural',\n",
       "   'pos': 'adjective',\n",
       "   'strength': 'strong'}),\n",
       " ('modum',\n",
       "  {'case': 'dative',\n",
       "   'gender': 'neuter',\n",
       "   'inflection': 'inflecting',\n",
       "   'number': 'plural',\n",
       "   'pos': 'common noun'}),\n",
       " ('lufien.',\n",
       "  {'inflection': 'non-inflecting',\n",
       "   'mood': 'infinitive',\n",
       "   'number': 'plural',\n",
       "   'pos': 'verb'})]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[0]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
